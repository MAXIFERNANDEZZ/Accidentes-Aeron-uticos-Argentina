import asyncio
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import pandas as pd
import time

url_base = "https://asn.flightsafety.org/database/"
datos = []

async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=True)  # Cambia a False si querés ver la ventana
        page = await browser.new_page()

        print("Abriendo página principal...")
        await page.goto(url_base)

        # Esperar que carguen los links con años
        await page.wait_for_selector("a[href*='dblist.php?Year=']", timeout=15000)

        links = await page.query_selector_all("a[href*='dblist.php?Year=']")
        links_años = [await link.get_attribute("href") for link in links]

        print(f"Encontrados {len(links_años)} años.")

        for idx, link in enumerate(links_años, 1):
            url = url_base + link if link.startswith("dblist.php") else link
            print(f"[{idx}/{len(links_años)}] Procesando {url}")

            await page.goto(url)
            try:
                await page.wait_for_selector("table.dbtable", timeout=15000)
            except:
                print(f"No se encontró tabla en {url}")
                continue

            html = await page.content()
            soup = BeautifulSoup(html, "html.parser")
            tabla = soup.find("table", class_="dbtable")

            if not tabla:
                print(f"No se encontró tabla en {url}")
                continue

            año = int(url.split('=')[-1])
            filas = tabla.find_all("tr")

            for fila in filas[1:]:
                celdas = fila.find_all("td")
                if len(celdas) >= 7:
                    datos.append({
                        "Año": año,
                        "Fecha": celdas[0].text.strip(),
                        "Tipo": celdas[1].text.strip(),
                        "Matrícula": celdas[2].text.strip(),
                        "Operador": celdas[3].text.strip(),
                        "Fallecidos": celdas[4].text.strip(),
                        "Ubicación": celdas[5].text.strip(),
                        "Daño": celdas[6].text.strip()
                    })
            time.sleep(1)  # para no saturar el servidor

        await browser.close()

    df = pd.DataFrame(datos)
    df.to_csv("asn_accidentes_completo_playwright.csv", index=False)
    print(f"✅ Listo. Archivo generado con {len(df)} registros.")

if __name__ == "__main__":
    asyncio.run(main())
